{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Taller 4: Neural Networks and Deep Learning\n",
    "#$Integrantes$:\n",
    ">Juan Felipe Baquero Vargas\n",
    "\n",
    ">Lina Fernanda Rosales Castro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Download the code and run the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\t\t     linear_decoder_exercise.py  softmax_exercise.py\r\n",
      "README.md\t     load_MNIST.py\t\t sparse_autoencoder.py\r\n",
      "cnn.py\t\t     load_MNIST.pyc\t\t sparse_autoencoder.pyc\r\n",
      "cnn_exercise.py      load_images.py\t\t stacked_ae_exercise.py\r\n",
      "data\t\t     output\t\t\t stacked_autoencoder.py\r\n",
      "display_network.py   pca_gen.py\t\t\t stacked_autoencoder.pyc\r\n",
      "display_network.pyc  sample_images.py\t\t stl_exercise.py\r\n",
      "gradient.py\t     sample_images.pyc\t\t train.py\r\n",
      "gradient.pyc\t     softmax.py\r\n",
      "iterate.dat\t     softmax.pyc\r\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'ufldl_tutorial/'\n",
      "/home/jfbaquerov/MachineLearning/ufldl_tutorial\n"
     ]
    }
   ],
   "source": [
    "cd ufldl_tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"softmax_exercise.py\", line 69\n",
      "    print num_grad, grad\n",
      "                 ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python softmax_exercise.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"train.py\", line 78\n",
      "    print cost, grad\n",
      "             ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos codigos presentaron problemas al correr desde el notebook de python asi que se corrio directamente desde consola, se adjuntas imagenes de la ejecucion y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jfbaquerov/MachineLearning\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagen en la que se inicia  la ejecucion de train.py\n",
    "<img src=\"imagenes_entrega/Punto3_1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando termino la ejecucion por exceder el numero de iteraciones:\n",
    "<img src=\"imagenes_entrega/Punto3_2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resumen de la ejecucion:\n",
    "<img src=\"imagenes_entrega/Punto3_3.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos fueron:\n",
    "<img src=\"imagenes_entrega/weights.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar softmax_exercise\n",
    "<img src=\"imagenes_entrega/Punto3_sm1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fin de la ejecucion por exceder el numero maximo de iteraciones:\n",
    "<img src=\"imagenes_entrega/Punto3_sm2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final softMax Presento un Accuracy de **92.31%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##B) Modify the code to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jfbaquerov/MachineLearning/ufldl_tutorial\n"
     ]
    }
   ],
   "source": [
    "cd ufldl_tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\t\t     linear_decoder_exercise.py  softmax_exercise.py\r\n",
      "README.md\t     load_MNIST.py\t\t sparse_autoencoder.py\r\n",
      "cnn.py\t\t     load_MNIST.pyc\t\t sparse_autoencoder.pyc\r\n",
      "cnn_exercise.py      load_images.py\t\t stacked_ae_exercise.py\r\n",
      "data\t\t     output\t\t\t stacked_autoencoder.py\r\n",
      "display_network.py   pca_gen.py\t\t\t stacked_autoencoder.pyc\r\n",
      "display_network.pyc  sample_images.py\t\t stl_exercise.py\r\n",
      "gradient.py\t     sample_images.pyc\t\t train.py\r\n",
      "gradient.pyc\t     softmax.py\t\t\t weights.png\r\n",
      "iterate.dat\t     softmax.pyc\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una copia de train.py llamada train2.py, la cual sera la modificacion agregando la funcion de costo RICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\t\t     linear_decoder_exercise.py  softmax_exercise.py\r\n",
      "README.md\t     load_MNIST.py\t\t sparse_autoencoder.py\r\n",
      "cnn.py\t\t     load_MNIST.pyc\t\t sparse_autoencoder.pyc\r\n",
      "cnn_exercise.py      load_images.py\t\t stacked_ae_exercise.py\r\n",
      "data\t\t     output\t\t\t stacked_autoencoder.py\r\n",
      "display_network.py   pca_gen.py\t\t\t stacked_autoencoder.pyc\r\n",
      "display_network.pyc  sample_images.py\t\t stl_exercise.py\r\n",
      "gradient.py\t     sample_images.pyc\t\t train.py\r\n",
      "gradient.pyc\t     softmax.py\t\t\t train2.py\r\n",
      "iterate.dat\t     softmax.pyc\t\t weights.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\r\n",
      "import scipy.optimize\r\n",
      "import sample_images\r\n",
      "import sparse_autoencoder\r\n",
      "import gradient\r\n",
      "import display_network\r\n",
      "import load_MNIST\r\n",
      "\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP 0: Here we provide the relevant parameters values that will\r\n",
      "#  allow your sparse autoencoder to get good filters; you do not need to\r\n",
      "#  change the parameters below.\r\n",
      "\r\n",
      "# number of input units\r\n",
      "visible_size = 28 * 28\r\n",
      "# number of input units\r\n",
      "hidden_size = 196\r\n",
      "\r\n",
      "# desired average activation of the hidden units.\r\n",
      "# (This was denoted by the Greek alphabet rho, which looks like a lower-case \"p\",\r\n",
      "#  in the lecture notes).\r\n",
      "sparsity_param = 0.1\r\n",
      "# weight decay parameter\r\n",
      "lambda_ = 3e-3\r\n",
      "# weight of sparsity penalty term\r\n",
      "beta = 3\r\n",
      "# debug\r\n",
      "debug = False\r\n",
      "\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP 1: Implement sampleIMAGES\r\n",
      "#\r\n",
      "#  After implementing sampleIMAGES, the display_network command should\r\n",
      "#  display a random sample of 200 patches from the dataset\r\n",
      "\r\n",
      "# Loading Sample Images\r\n",
      "# patches = sample_images.sample_images()\r\n",
      "\r\n",
      "# Loading 10K images from MNIST database\r\n",
      "images = load_MNIST.load_MNIST_images('data/mnist/train-images-idx3-ubyte')\r\n",
      "patches = images[:, 0:10000]\r\n",
      "\r\n",
      "#  Obtain random parameters theta\r\n",
      "theta = sparse_autoencoder.initialize(hidden_size, visible_size)\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP 2: Implement sparseAutoencoderCost\r\n",
      "#\r\n",
      "#  You can implement all of the components (squared error cost, weight decay term,\r\n",
      "#  sparsity penalty) in the cost function at once, but it may be easier to do\r\n",
      "#  it step-by-step and run gradient checking (see STEP 3) after each step.  We\r\n",
      "#  suggest implementing the sparseAutoencoderCost function using the following steps:\r\n",
      "#\r\n",
      "#  (a) Implement forward propagation in your neural network, and implement the\r\n",
      "#      squared error term of the cost function.  Implement backpropagation to\r\n",
      "#      compute the derivatives.   Then (using lambda=beta=0), run Gradient Checking\r\n",
      "#      to verify that the calculations corresponding to the squared error cost\r\n",
      "#      term are correct.\r\n",
      "#\r\n",
      "#  (b) Add in the weight decay term (in both the cost function and the derivative\r\n",
      "#      calculations), then re-run Gradient Checking to verify correctness.\r\n",
      "#\r\n",
      "#  (c) Add in the sparsity penalty term, then re-run Gradient Checking to\r\n",
      "#      verify correctness.\r\n",
      "#\r\n",
      "#  Feel free to change the training settings when debugging your\r\n",
      "#  code.  (For example, reducing the training set size or\r\n",
      "#  number of hidden units may make your code run faster; and setting beta\r\n",
      "#  and/or lambda to zero may be helpful for debugging.)  However, in your\r\n",
      "#  final submission of the visualized weights, please use parameters we\r\n",
      "#  gave in Step 0 above.\r\n",
      "\r\n",
      "(cost, grad) = sparse_autoencoder.sparse_autoencoder_cost(theta, visible_size,\r\n",
      "                                                          hidden_size, lambda_,\r\n",
      "                                                          sparsity_param, beta, patches)\r\n",
      "print cost, grad\r\n",
      "##======================================================================\r\n",
      "## STEP 3: Gradient Checking\r\n",
      "#\r\n",
      "# Hint: If you are debugging your code, performing gradient checking on smaller models\r\n",
      "# and smaller training sets (e.g., using only 10 training examples and 1-2 hidden\r\n",
      "# units) may speed things up.\r\n",
      "\r\n",
      "# First, lets make sure your numerical gradient computation is correct for a\r\n",
      "# simple function.  After you have implemented computeNumericalGradient.m,\r\n",
      "# run the following:\r\n",
      "\r\n",
      "\r\n",
      "if debug:\r\n",
      "    gradient.check_gradient()\r\n",
      "\r\n",
      "    # Now we can use it to check your cost function and derivative calculations\r\n",
      "    # for the sparse autoencoder.\r\n",
      "    # J is the cost function\r\n",
      "\r\n",
      "    J = lambda x: sparse_autoencoder.sparse_autoencoder_cost(x, visible_size, hidden_size,\r\n",
      "                                                             lambda_, sparsity_param,\r\n",
      "                                                             beta, patches)\r\n",
      "    num_grad = gradient.compute_gradient(J, theta)\r\n",
      "\r\n",
      "    # Use this to visually compare the gradients side by side\r\n",
      "    print num_grad, grad\r\n",
      "\r\n",
      "    # Compare numerically computed gradients with the ones obtained from backpropagation\r\n",
      "    diff = np.linalg.norm(num_grad - grad) / np.linalg.norm(num_grad + grad)\r\n",
      "    print diff\r\n",
      "    print \"Norm of the difference between numerical and analytical num_grad (should be < 1e-9)\\n\\n\"\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP 4: After verifying that your implementation of\r\n",
      "#  sparseAutoencoderCost is correct, You can start training your sparse\r\n",
      "#  autoencoder with minFunc (L-BFGS).\r\n",
      "\r\n",
      "#  Randomly initialize the parameters\r\n",
      "theta = sparse_autoencoder.initialize(hidden_size, visible_size)\r\n",
      "\r\n",
      "J = lambda x: sparse_autoencoder.sparse_autoencoder_cost(x, visible_size, hidden_size,\r\n",
      "                                                         lambda_, sparsity_param,\r\n",
      "                                                         beta, patches)\r\n",
      "options_ = {'maxiter': 400, 'disp': True}\r\n",
      "result = scipy.optimize.minimize(J, theta, method='L-BFGS-B', jac=True, options=options_)\r\n",
      "opt_theta = result.x\r\n",
      "\r\n",
      "print result\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP 5: Visualization\r\n",
      "\r\n",
      "W1 = opt_theta[0:hidden_size * visible_size].reshape(hidden_size, visible_size).transpose()\r\n",
      "display_network.display_network(W1)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el archivo de train se modificara el **Paso 4** cambiando el calculo del costo del sparse_autoencoder por el calculo propuesto por el enunciado del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$min_W(\\lambda*||Wx||_1+1/2*||W^tWx-x||^2_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer esto se realiza el cambio en:\n",
    ">J = lambda x: sparse_autoencoder.sparse_autoencoder_cost(x, visible_size, hidden_size,lambda_, sparsity_param,beta, patches)\n",
    "\n",
    "por:\n",
    ">J = lambda x: RICA_cost(x, visible_size, hidden_size,lambda_, sparsity_param,beta, patches)\n",
    "                                                         \n",
    "                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde se definio Rica cost como se muestra acontinuacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RICA_cost(theta, visible_size, hidden_size, lambda_,\n",
    "              sparsity_param,beta, data):\n",
    "    #Lo siguiente es la misma tranformacion de datos que realizan en el sparse_autoencoder_cost\n",
    "    \n",
    "    # The input theta is a vector (because minFunc expects the parameters to be a vector).\n",
    "    # We first convert theta to the (W1, W2, b1, b2) matrix/vector format, so that this\n",
    "    # follows the notation convention of the lecture notes.\n",
    "\n",
    "    W1 = theta[0:hidden_size * visible_size].reshape(hidden_size, visible_size)\n",
    "    W2 = theta[hidden_size * visible_size:2 * hidden_size * visible_size].reshape(visible_size, hidden_size)\n",
    "    b1 = theta[2 * hidden_size * visible_size:2 * hidden_size * visible_size + hidden_size]\n",
    "    b2 = theta[2 * hidden_size * visible_size + hidden_size:]\n",
    "    \n",
    "    # Number of training examples\n",
    "    m = data.shape[1]\n",
    "\n",
    "    eps =  np.tile(b1, (m, 1)).transpose()\n",
    "    # Forward propagation\n",
    "    z2 = W1.dot(data)**2 \n",
    "    #a2 = sigmoid(z2)\n",
    "    z3 = W2.dot(a2) + np.tile(b2, (m, 1)).transpose()\n",
    "    #h = sigmoid(z3)\n",
    "    wx = np.sqrt( np.sum(z2 +eps) )\n",
    "    wTwx = 0.5*np.sum( W.T.dot( W.dot(x) )-x + eps )\n",
    "    \n",
    "    cost = (lambda_*wx+wTwx)/m\n",
    "    \n",
    "    gradient = lambda_ * np.dot(np.dot(W, x) / wx, x.T)\n",
    "    grad = (gradient + np.dot(np.dot(W, wTwx), x.T) + np.dot(np.dot(W, x), wTwx.T) ) / m\n",
    "    \n",
    "    return cost, grad\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un nuevo train que es la copia del anterior pero con los cambios comentados, acontinucacion se muestra el archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\r\n",
      "import scipy.optimize\r\n",
      "import sample_images\r\n",
      "import sparse_autoencoder\r\n",
      "import gradient\r\n",
      "import display_network\r\n",
      "import load_MNIST\r\n",
      "\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP -1: We create a RICA cost function\r\n",
      "def RICA_cost(theta, visible_size, hidden_size, lambda_,\r\n",
      "              sparsity_param,beta, data):\r\n",
      "    #Lo siguiente es la misma tranformacion de datos que realizan en el sparse_autoencoder_cost\r\n",
      "    \r\n",
      "    # The input theta is a vector (because minFunc expects the parameters to be a vector).\r\n",
      "    # We first convert theta to the (W1, W2, b1, b2) matrix/vector format, so that this\r\n",
      "    # follows the notation convention of the lecture notes.\r\n",
      "\r\n",
      "    W1 = theta[0:hidden_size * visible_size].reshape(hidden_size, visible_size)\r\n",
      "    W2 = theta[hidden_size * visible_size:2 * hidden_size * visible_size].reshape(visible_size, hidden_size)\r\n",
      "    b1 = theta[2 * hidden_size * visible_size:2 * hidden_size * visible_size + hidden_size]\r\n",
      "    b2 = theta[2 * hidden_size * visible_size + hidden_size:]\r\n",
      "    \r\n",
      "\t# Number of training examples\r\n",
      "    m = data.shape[1]\r\n",
      "\t\r\n",
      "\teps =  np.tile(b1, (m, 1)).transpose()\r\n",
      "\t# Forward propagation\r\n",
      "    z2 = W1.dot(data)**2 \r\n",
      "    #a2 = sigmoid(z2)\r\n",
      "    z3 = W2.dot(a2) + np.tile(b2, (m, 1)).transpose()\r\n",
      "    #h = sigmoid(z3)\r\n",
      "\twx = np.sqrt( np.sum(z2 +eps) )\r\n",
      "\twTwx = 0.5*np.sum( W.T.dot( W.dot(x) )-x + eps )\r\n",
      "\t\r\n",
      "\tcost = (lambda_*wx+wTwx)/m\r\n",
      "\t\r\n",
      "\tgradient = lambda_ * np.dot(np.dot(W, x) / wx, x.T)\r\n",
      "    grad = (gradient + np.dot(np.dot(W, wTwx), x.T) + np.dot(np.dot(W, x), wTwx.T) ) / m\r\n",
      "\t\r\n",
      "\treturn cost, grad\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP 0: Here we provide the relevant parameters values that will\r\n",
      "#  allow your sparse autoencoder to get good filters; you do not need to\r\n",
      "#  change the parameters below.\r\n",
      "\r\n",
      "# number of input units\r\n",
      "visible_size = 28 * 28\r\n",
      "# number of input units\r\n",
      "hidden_size = 196\r\n",
      "\r\n",
      "# desired average activation of the hidden units.\r\n",
      "# (This was denoted by the Greek alphabet rho, which looks like a lower-case \"p\",\r\n",
      "#  in the lecture notes).\r\n",
      "sparsity_param = 0.1\r\n",
      "# weight decay parameter\r\n",
      "lambda_ = 3e-3\r\n",
      "# weight of sparsity penalty term\r\n",
      "beta = 3\r\n",
      "# debug\r\n",
      "debug = False\r\n",
      "\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP 1: Implement sampleIMAGES\r\n",
      "#\r\n",
      "#  After implementing sampleIMAGES, the display_network command should\r\n",
      "#  display a random sample of 200 patches from the dataset\r\n",
      "\r\n",
      "# Loading Sample Images\r\n",
      "# patches = sample_images.sample_images()\r\n",
      "\r\n",
      "# Loading 10K images from MNIST database\r\n",
      "images = load_MNIST.load_MNIST_images('data/mnist/train-images-idx3-ubyte')\r\n",
      "patches = images[:, 0:10000]\r\n",
      "\r\n",
      "#  Obtain random parameters theta\r\n",
      "theta = sparse_autoencoder.initialize(hidden_size, visible_size)\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP 2: Implement sparseAutoencoderCost\r\n",
      "#\r\n",
      "#  You can implement all of the components (squared error cost, weight decay term,\r\n",
      "#  sparsity penalty) in the cost function at once, but it may be easier to do\r\n",
      "#  it step-by-step and run gradient checking (see STEP 3) after each step.  We\r\n",
      "#  suggest implementing the sparseAutoencoderCost function using the following steps:\r\n",
      "#\r\n",
      "#  (a) Implement forward propagation in your neural network, and implement the\r\n",
      "#      squared error term of the cost function.  Implement backpropagation to\r\n",
      "#      compute the derivatives.   Then (using lambda=beta=0), run Gradient Checking\r\n",
      "#      to verify that the calculations corresponding to the squared error cost\r\n",
      "#      term are correct.\r\n",
      "#\r\n",
      "#  (b) Add in the weight decay term (in both the cost function and the derivative\r\n",
      "#      calculations), then re-run Gradient Checking to verify correctness.\r\n",
      "#\r\n",
      "#  (c) Add in the sparsity penalty term, then re-run Gradient Checking to\r\n",
      "#      verify correctness.\r\n",
      "#\r\n",
      "#  Feel free to change the training settings when debugging your\r\n",
      "#  code.  (For example, reducing the training set size or\r\n",
      "#  number of hidden units may make your code run faster; and setting beta\r\n",
      "#  and/or lambda to zero may be helpful for debugging.)  However, in your\r\n",
      "#  final submission of the visualized weights, please use parameters we\r\n",
      "#  gave in Step 0 above.\r\n",
      "\r\n",
      "(cost, grad) = sparse_autoencoder.sparse_autoencoder_cost(theta, visible_size,\r\n",
      "                                                          hidden_size, lambda_,\r\n",
      "                                                          sparsity_param, beta, patches)\r\n",
      "print cost, grad\r\n",
      "##======================================================================\r\n",
      "## STEP 3: Gradient Checking\r\n",
      "#\r\n",
      "# Hint: If you are debugging your code, performing gradient checking on smaller models\r\n",
      "# and smaller training sets (e.g., using only 10 training examples and 1-2 hidden\r\n",
      "# units) may speed things up.\r\n",
      "\r\n",
      "# First, lets make sure your numerical gradient computation is correct for a\r\n",
      "# simple function.  After you have implemented computeNumericalGradient.m,\r\n",
      "# run the following:\r\n",
      "\r\n",
      "\r\n",
      "if debug:\r\n",
      "    gradient.check_gradient()\r\n",
      "\r\n",
      "    # Now we can use it to check your cost function and derivative calculations\r\n",
      "    # for the sparse autoencoder.\r\n",
      "    # J is the cost function\r\n",
      "\r\n",
      "    J = lambda x: RICA_cost(x, visible_size, hidden_size,lambda_, sparsity_param,beta, patches)\r\n",
      "    num_grad = gradient.compute_gradient(J, theta)\r\n",
      "\r\n",
      "    # Use this to visually compare the gradients side by side\r\n",
      "    print num_grad, grad\r\n",
      "\r\n",
      "    # Compare numerically computed gradients with the ones obtained from backpropagation\r\n",
      "    diff = np.linalg.norm(num_grad - grad) / np.linalg.norm(num_grad + grad)\r\n",
      "    print diff\r\n",
      "    print \"Norm of the difference between numerical and analytical num_grad (should be < 1e-9)\\n\\n\"\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP 4: After verifying that your implementation of\r\n",
      "#  sparseAutoencoderCost is correct, You can start training your sparse\r\n",
      "#  autoencoder with minFunc (L-BFGS).\r\n",
      "\r\n",
      "#  Randomly initialize the parameters\r\n",
      "theta = sparse_autoencoder.initialize(hidden_size, visible_size)\r\n",
      "\r\n",
      "J = lambda x: sparse_autoencoder.sparse_autoencoder_cost(x, visible_size, hidden_size,\r\n",
      "                                                         lambda_, sparsity_param,\r\n",
      "                                                         beta, patches)\r\n",
      "options_ = {'maxiter': 400, 'disp': True}\r\n",
      "result = scipy.optimize.minimize(J, theta, method='L-BFGS-B', jac=True, options=options_)\r\n",
      "opt_theta = result.x\r\n",
      "\r\n",
      "print result\r\n",
      "\r\n",
      "##======================================================================\r\n",
      "## STEP 5: Visualization\r\n",
      "\r\n",
      "W1 = opt_theta[0:hidden_size * visible_size].reshape(hidden_size, visible_size).transpose()\r\n",
      "display_network.display_network(W1)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat train2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados Luego del cambio fueron:\n",
    "<img src=\"imagenes_entrega/weights_22.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Al ejecutar softmax_excersise con el nuevo costo los resultados fueron:\n",
    "<img src=\"imagenes_entrega/punto3_C1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "El cambio de la función en el primer ejercicio de Vectorizacion nos mostro unas imagenes un poco mas difusas, lo cual seria un mejor desempeño, ya que esto es lo podido en el ejercicio del tutorial.\n",
    "\n",
    "Para el ejercicio de Sofmax_Regression, la mejora fue muy poca paso del **92.31** al **92.43** acercandose mas al objetivo de ***92.6***, el cambio de funcion objetivo acerco mas al accuracy que se buscaba en el taller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
